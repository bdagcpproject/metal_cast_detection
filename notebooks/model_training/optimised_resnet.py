# -*- coding: utf-8 -*-
"""Optimised RESNET.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v_RqwH9xuZEwVYHImdZmKaI7OE_uJOIS
"""

!pip install -q kaggle torch torchvision matplotlib opencv-python

from google.colab import files
files.upload()  # Upload kaggle.json

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!ls /content/casting_data/casting_data/casting_data/train/def_front/ | wc -l #check if files are there from active sessions

#If no files from other active sessions
!kaggle datasets download -d ravirajsinh45/real-life-industrial-dataset-of-casting-product
!unzip real-life-industrial-dataset-of-casting-product -d /content/casting_data
!mv  /content/casting_data/casting_data/casting_data/test/ok_front/* /content/casting_data/casting_data/casting_data/train/ok_front/
!mv  /content/casting_data/casting_data/casting_data/test/def_front/* /content/casting_data/casting_data/casting_data/train/def_front/

import os
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import numpy as np
import torch.optim as optim
from torch import nn

# Dataset Preparation
class CastingDataset(Dataset):
    def __init__(self, root_dir, transforms=None, imgs=None, labels=None):
        self.root_dir = root_dir
        self.transforms = transforms
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        img_path = self.imgs[idx]
        label = self.labels[idx]

        # Load image
        image = Image.open(img_path).convert("RGB")

        # Apply transformations (resize, normalize, etc.)
        if self.transforms:
            image = self.transforms(image)

        return image, label

# Define Image Transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize images (standard for ResNet)
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats
])

# Define paths for dataset
defective_path = "casting_data/casting_data/casting_data/train/def_front/"
ok_path = "casting_data/casting_data/casting_data/train/ok_front/"

# Collect images from both folders
defective_imgs = sorted(os.listdir(defective_path))
ok_imgs = sorted(os.listdir(ok_path))

# Store full paths
imgs = [os.path.join(defective_path, img) for img in defective_imgs] + \
       [os.path.join(ok_path, img) for img in ok_imgs]

# Corresponding labels (1 = defective, 0 = ok)
labels = [1] * len(defective_imgs) + [0] * len(ok_imgs)

# Split dataset into training and validation (80/20)
train_imgs, val_imgs, train_labels, val_labels = train_test_split(imgs, labels, test_size=0.3, random_state=42)

# Create Dataset and DataLoader for Training and Validation
train_dataset = CastingDataset(root_dir="casting_data", transforms=transform, imgs=train_imgs, labels=train_labels)
val_dataset = CastingDataset(root_dir="casting_data", transforms=transform, imgs=val_imgs, labels=val_labels)

train_data_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
val_data_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)

# 2. ResNet Model Setup
model = models.resnet50(pretrained=True)  # You can use ResNet-18, ResNet-34, etc.
# Modify the final layer to output 2 classes
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 2)  # 2 classes: defective (1) and ok (0)

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# 3. Loss and Optimizer
criterion = nn.CrossEntropyLoss()  # Cross entropy loss for classification
optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)

# 4. Training Loop (Train for 10 epochs)
num_epochs = 10  # Set the number of epochs to 10
for epoch in range(num_epochs):
    model.train()  # Set model to training mode
    running_loss = 0.0

    for images, labels in train_data_loader:
        images, labels = images.to(device), labels.to(device)

        # Zero the parameter gradients
        optimizer.zero_grad()

        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)

        # Backward pass
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_data_loader):.4f}")

print("Training complete!")

# 5. Evaluate with Confusion Matrix on Validation Set
model.eval()  # Set model to evaluation mode
all_preds = []
all_labels = []

# Run the model on the entire validation set to collect predictions
with torch.no_grad():
    for images, labels in val_data_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, preds = torch.max(outputs, 1)

        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# 6. Compute Confusion Matrix
cm = confusion_matrix(all_labels, all_preds)

# 7. Plot Confusion Matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['OK', 'Defective'], yticklabels=['OK', 'Defective'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

print("Classification Report:")
print(classification_report(all_labels, all_preds, target_names=["OK", "Defective"]))