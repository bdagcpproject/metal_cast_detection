# -*- coding: utf-8 -*-
"""Optimised Casting Faster R-CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BSIeDblGVRNUTmoxQkObewozHE0odxOe
"""

!pip install -q kaggle torch torchvision matplotlib opencv-python

from google.colab import files
files.upload()  # Upload kaggle.json

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d ravirajsinh45/real-life-industrial-dataset-of-casting-product
!unzip real-life-industrial-dataset-of-casting-product -d /content/casting_data

!mv  /content/casting_data/casting_data/casting_data/test/ok_front/* /content/casting_data/casting_data/casting_data/train/ok_front/
!mv  /content/casting_data/casting_data/casting_data/test/def_front/* /content/casting_data/casting_data/casting_data/train/def_front/

!pwd

!ls ../content/sample_data

!ls /content/casting_data/casting_data/casting_data/train/def_front/ | wc -l

!ls /content/casting_data/casting_data/casting_data/train/ok_front/ | wc -l



import os
import torch
import torchvision
import numpy as np
import cv2
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import ConfusionMatrixDisplay
import random
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor


# Define the CastingDataset class
class CastingDataset(Dataset):
    def __init__(self, root_dir, transforms=None, split='train'):
        self.root_dir = root_dir
        self.transforms = transforms
        self.split = split

        # Define paths for train and test sets
        defective_path = os.path.join(root_dir, "/content/casting_data/casting_data/casting_data/train/def_front/")
        ok_path = os.path.join(root_dir, "/content/casting_data/casting_data/casting_data/train/ok_front/")

        # Collect images from both folders
        defective_imgs = sorted(os.listdir(defective_path))
        ok_imgs = sorted(os.listdir(ok_path))

        # Store full paths
        self.imgs = [os.path.join(defective_path, img) for img in defective_imgs] + \
                    [os.path.join(ok_path, img) for img in ok_imgs]

        # Corresponding labels (1 = defective, 0 = ok)
        self.labels = [1] * len(defective_imgs) + [0] * len(ok_imgs)

        # Split dataset into training and validation sets
        train_imgs, val_imgs, train_labels, val_labels = train_test_split(self.imgs, self.labels, test_size=0.3, random_state=42)

        if self.split == 'train':
            self.imgs = train_imgs
            self.labels = train_labels
        elif self.split == 'val':
            self.imgs = val_imgs
            self.labels = val_labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        img_path = self.imgs[idx]
        label = self.labels[idx]

        # Load image
        image = Image.open(img_path).convert("RGB")

        # Generate synthetic bounding boxes (since dataset lacks annotations)
        width, height = image.size
        boxes = torch.tensor([[10, 10, width - 10, height - 10]], dtype=torch.float32)  # Entire image as bounding box
        labels = torch.tensor([label], dtype=torch.int64)  # Label (1 = defective, 0 = ok)

        # Convert to target format
        target = {"boxes": boxes, "labels": labels}

        # Apply transforms if available
        if self.transforms:
            image = self.transforms(image)

        return image, target  # Return image and dictionary

# Define Image Transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize images (optional)
    transforms.ToTensor(),
])

# Load Dataset for training and validation
train_dataset = CastingDataset(root_dir="content", transforms=transform, split='train')
val_dataset = CastingDataset(root_dir="content", transforms=transform, split='val')

# Get DataLoader with optimizations for faster execution
def collate_fn(batch):
    images = []
    targets = []
    for image, target in batch:
        images.append(image)   # Append images directly
        targets.append(target) # Append target dictionaries directly
    return images, targets  # Returns lists directly

# Create DataLoader
train_data_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn, num_workers=4, pin_memory=True)
val_data_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn, num_workers=4, pin_memory=True)

# Check dataset loading
for images, targets in train_data_loader:
    print(f"Batch size: {len(images)}")
    print(f"Example target: {targets[0]}")  # Print target dictionary
    break  # Print only first batch

# Load Faster R-CNN Pretrained on COCO
model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)

# Modify the classifier to detect casting defects (2 classes: defective, background)
num_classes = 2  # 1 (Defective) + Background
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

# Move model to GPU if available
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Define optimizer & learning rate scheduler
params = [p for p in model.parameters() if p.requires_grad]
optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)
lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)

num_epochs = 10  # Increase the number of epochs to 10

# Train the model for 10 epochs
for epoch in range(num_epochs):
    model.train()
    epoch_loss = 0

    for images, targets in train_data_loader:
        images = list(img.to(device) for img in images)
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

        optimizer.zero_grad()
        loss_dict = model(images, targets)
        losses = sum(loss for loss in loss_dict.values())

        losses.backward()
        optimizer.step()

        epoch_loss += losses.item()

    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}")
    lr_scheduler.step()

print("Training Complete!")

# Evaluation on Validation Set
model.eval()
all_preds = []
all_labels = []

# Loop through validation dataset
with torch.no_grad():
    for images, targets in val_data_loader:
        images = [img.to(device) for img in images]
        outputs = model(images)

        for output, target in zip(outputs, targets):
            true_label = target["labels"].item()
            all_labels.append(true_label)

            if len(output["boxes"]) > 0 and output["scores"][0] > 0.5:  # Threshold 0.5
                pred_label = 1  # Defective
            else:
                pred_label = 0  # OK (No defect detected)

            all_preds.append(pred_label)

# Convert to numpy arrays
all_labels = np.array(all_labels)
all_preds = np.array(all_preds)

# Compute Confusion Matrix
cm = confusion_matrix(all_labels, all_preds, labels=[0, 1])

# Plot Confusion Matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["OK (0)", "Defective (1)"])
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix - Casting Defect Detection")
plt.show()

print("Classification Report:")
print(classification_report(all_labels, all_preds, target_names=["OK", "Defective"]))

# Test on one defect image
model.eval()
img_path = "casting_data/casting_data/casting_data/train/def_front/cast_def_0_9150.jpeg"
img = Image.open(img_path).convert("RGB")
img_tensor = transform(img).unsqueeze(0).to(device)

# Run Inference
with torch.no_grad():
    prediction = model(img_tensor)

# Visualize the result
img_np = np.array(img)
boxes = prediction[0]['boxes'].cpu().numpy()
scores = prediction[0]['scores'].cpu().numpy()

for i, box in enumerate(boxes):
    if scores[i] > 0.5:  # Confidence Threshold
        x_min, y_min, x_max, y_max = map(int, box)
        cv2.rectangle(img_np, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

plt.imshow(img_np)
plt.axis("off")
plt.show()